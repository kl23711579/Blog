---
title: "1/9 é–’èŠ"
date: 2020-01-10T00:24:54+10:00
draft: false
showDate: true
tags: ["Hugo", "Python", "scrapy", "pip"]
---

# DebugXPythonXCrawler

<!--more-->

å…ˆä¾†é¦–æ­Œå§ï¼Œæ›¾ç¶“è”šè—ï¼Œå°ç£é™å®š ğŸ’œğŸ’™

{{< youtube TRTquokWSCw >}}

# Debug

æ˜¨å¤©å·®é» debug åˆ°å´©æ½°ï¼Œå®Œå…¨ä¸çŸ¥é“å‡ºäº†ä»€éº¼éŒ¯èª¤

å› ç‚º bug ç„¡æ³•é‡ç¾ï¼Œæ‰€ä»¥ä¹‹å¾Œå‡ºç¾å†è£œåœ–å§

æ±ç¿»è¥¿æ‰¾ï¼ŒåŸæœ¬ä»¥ç‚ºæ˜¯ theme çš„ layout æœ‰å•é¡Œ

æäº†åŠå¤©çµæœä¸æ˜¯ QQ

## bug

> Mixed content error

æœ€å´©æ½°çš„æ˜¯ï¼Œé–‹ç™¼è€…æ¨¡å¼å®Œå…¨ç„¡æ³•æ‰¾åˆ° bug æ˜¯æ€éº¼ç™¼ç”Ÿçš„

å‡ºç¾çš„ä½ç½®æ˜¯ `(index):1 error` ä¹Ÿå°±æ˜¯ `<!DOCTYPE html>`

å®Œå…¨å•è™Ÿï¼Œä¸çŸ¥é“æ€éº¼è™•ç† T T 

## Solution

å¾Œä¾†æ‰¾åˆ°çš„ç­”æ¡ˆæ˜¯æŠŠ baseURL æ”¹æ‰

å¾ `baseURL= 'https://kl23711579.github.io/blog'` è®Šæˆ `baseURL= '/blog'`

é€™æ¨£å°±å¯ä»¥äº†

ç†ç”±å‘¢ï¼Œå®Œå…¨ä¸çŸ¥é“ï¼ŒçœŸçœŸæ­£æ­£çš„æŠ€è¡“å‚µå•Šï½

Source: [Theme breaks with https? [SOLVED by baseURL = //example.com]](https://discourse.gohugo.io/t/theme-breaks-with-https-solved-by-baseurl-example-com/16427)

# Python and pip

ä»Šå¤©å› ç‚ºè¦å¯«å€‹çˆ¬èŸ²(æ•´å¤©æœ‰äº‹æ²’äº‹éƒ½åœ¨å¯«çˆ¬èŸ²)ï¼Œæƒ³èªªé †ä¾¿è¦ç·´ç¿’ python

æ‰€ä»¥é¸æ“‡äº† scrapyï¼Œä¸€å®‰è£ä¸‹å»å°±æ˜¯æ‚²åŠ‡çš„é–‹å§‹å•Š

å› ç‚º dependence å¤ªå¤šäº†ï¼Œæ‰€ä»¥ pip è®Šå¾—å¾ˆé›£ç®¡ç†

å†åŠ ä¸Š pip æ²’è¨­å®šå¥½ï¼Œé‚„æ˜¯ç¹¼çºŒç”¨ python2ï¼Œä¹Ÿè¦é‡æ–°è¨­å®š

æ‰€ä»¥èŠ±äº†å¾ˆé•·ä¸€æ®µæ™‚é–“é‡æ–°è¨­å®š python

## Setup python and pip

é¦–å…ˆè¦å…ˆç¢ºå®š terminal æ˜¯ç”¨ä»€éº¼ shellï¼Œæˆ‘çš„æ˜¯ zshï¼Œæ‰€ä»¥è¦æ›´æ”¹ `.zshrc` é€™å€‹æª”æ¡ˆ

åŠ ä¸Šé€™å…©è¡Œ

```
alias python='python3'
alias pip='pip3'
```

In this situation, if we input `python` in terminal, it will execute `python3`.

And if we input `pip` in terminal, it will execute `pip3`.

ç„¶å¾Œ python å»ºè­°ç”¨ homebrew ç®¡ç†

Source: [The right and wrong way to set Python 3 as default on a Mac](https://opensource.com/article/19/5/python-3-default-mac)

## Virtual environment

In order to manage the dependence of the module, I deceide to adopt `virtualenv`.

This tool can create an isolated Python environment, so you can manage dependence in this environment.

### Install

`pip install --user virtualenv`

> It is discourage to use `sudo` to install module.

### Usage

- #### Create

`virtualenv temp`

It will create a directory `temp`

- #### Start virtual envuronment

`source temp/bin/activate`

This will change your `$PATH` so its first entry is the virtualenvâ€™s `bin/` directory. (You have to use source because it changes your shell environment in-place.) 

Now, when you install any module with `pip`, it belongs to this virtual environment.

- #### Leave virtual envuronment

`deactivate`

This command is used to leave the virtual environment.

- #### Output module

`pip freeze > requirement.txt`

- #### Remove the virtual environment

Make sure you leave the virtual environment

`rm -r temp`

å‰©ä¸‹é€²éšçš„ç”¨æ³•å°±å»æŸ¥ [document](https://virtualenv.pypa.io/en/stable/userguide/) å§ï¼ï¼ï¼

> macos å¯ä»¥ç”¨ [virtualenvwrapper](https://virtualenvwrapper.readthedocs.io/en/latest/index.html) ä¾†ç®¡ç† virtualenvï¼Œå¥½ç”¨ï¼ï¼ï¼

![20200109-1](/blog/img/20200109/20200109-1.png)

Source1: [Virtualenv Guide](https://virtualenv.pypa.io/en/stable/userguide/)

Source2: [Python_Virtualenv ç°¡å–®ç­†è¨˜](https://tech.r567tw.tw/python_virtualenv-%E7%B0%A1%E5%96%AE%E7%AD%86%E8%A8%98/)

## Removing dependencies

å°±æ˜¯æƒ³è¦æ•´ç† module ä½†æ˜¯ä¸çŸ¥é“å“ªå€‹å¯ä»¥åˆªå“ªå€‹ä¸å¯ä»¥ï¼Œæ‰€ä»¥å¾ˆéº»ç…©

åŸæœ¬æœ‰ä¸€å€‹ `pip-autoremove` çš„ module å¯ä»¥ç”¨ï¼Œä½†æ˜¯ä½œè€…å¥½åƒæ”¾æ£„æ›´æ–°äº†(abandon)

æ‰€ä»¥åœ¨ python3 æœƒæœ‰å•é¡Œï¼Œå°ï¼Œæˆ‘å°±æ˜¯ç”¨äº†ç„¶å¾Œç”¢ç”Ÿå•é¡Œ

é›–ç„¶èªªæœƒæœ‰å•é¡Œï¼Œä½†é‚„æ˜¯å¯ä»¥ç”¨é€™å€‹ä¾†å°‹æ‰¾ dependenciesï¼Œå†ä¸€å€‹ä¸€å€‹æ‰‹å‹•åˆªé™¤(è¶…ç´šéº»ç…©)

`pip-autoremove -l <module>`

ç„¶å¾ŒæŠŠåˆ—å‡ºä¾†çš„ module æ‰‹å‹•ä¸€å€‹ä¸€å€‹åˆªé™¤

![20200109-2](/blog/img/20200109/20200109-2.png)

### Warning  

> åƒè¬ä¸è¦ç”¨ pip-autoremove å»ç§»é™¤ moduleï¼Œæƒ…æ³æœƒè®Šç•°å¸¸è¤‡é›œ

Source: [stackoverflow](https://stackoverflow.com/questions/57470523/pip-uninstall-package-and-unique-dependencies)

Source: [pip-autoremove](https://github.com/invl/pip-autoremove)

## pipdeptree

å°±æ˜¯æŠŠ dependencies ç”¨æ¨¹ç‹€çš„æ¦‚å¿µè¡¨ç¤ºå‡ºä¾†

`pip install pipdeptree`

ä½¿ç”¨æ–¹æ³•å»çœ‹ [document](https://github.com/naiquevin/pipdeptree)ï¼Œé€™è£¡ä¾†èªªå¦‚ä½•è¼¸å‡ºæˆ graph

æœ‰å››å€‹æŒ‡ä»¤å¯ä»¥ç”¨

```
$ pipdeptree --graph-output dot > dependencies.dot
$ pipdeptree --graph-output pdf > dependencies.pdf
$ pipdeptree --graph-output png > dependencies.png
$ pipdeptree --graph-output svg > dependencies.svg
```

é€™å€‹è¦å®‰è£ [`GraphViz`](https://graphviz.org/)

`brew install GraphViz`

`pip install --user GraphViz`

å…©å€‹éƒ½è¦æ‰“ï¼ï¼ï¼

ä¸€é–‹å§‹åªæ‰“ä¸€å€‹ï¼Œå®³æˆ‘æè¶…ä¹…QQ

Source: [pipdeptree](https://github.com/naiquevin/pipdeptree)

# Scrapy

å°±æ˜¯çˆ¬èŸ²

## Install

`pip install scrapy`

> å¼·çƒˆå»ºè­°ä½¿ç”¨ virtual environment å®‰è£

### Create Project

`scrapy startproject IUBook`

ç„¶å¾Œåœ¨ spider è³‡æ–™å¤¾åº•ä¸‹å¯«è‡ªå·±çš„çˆ¬èŸ²

`touch IUBook/spiders/book_spider.py`

æ‰“ç¨‹å¼ï¼Œç…§å®˜ç¶²ä¸Š[ç¯„ä¾‹](https://docs.scrapy.org/en/latest/intro/tutorial.html#our-first-spider)è‡ªå·±æ”¹å°±å¥½äº†

### Cookie and Headers

å…ˆè¨­å®šå¥½ cookies å’Œ headersï¼Œç­‰ request æ™‚ä¸€èµ·é€å‡ºå»

```
cookies={'GUEST_PASSWORD': '000000'}
headers={'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11'}
```
```
yield scrapy.Request(url=url, headers=headers, cookies=cookies, callback=self.parse)
```

### Start

`scrapy crawl book`

`book` æ˜¯å› ç‚ºæˆ‘åå­—å– book

`name= "book"`

### Downloading Files [[link]](https://docs.scrapy.org/en/latest/topics/media-pipeline.html)

åœ¨ scrapy è£¡æ˜¯ä½¿ç”¨ `FilesPipeline` ä¾†ä¸‹è¼‰

- #### Setup

put this in `setting.py`

For image:
```
ITEM_PIPELINES = {'scrapy.pipelines.images.ImagesPipeline': 1}
IMAGES_STORE = '/path/to/valid/dir'
```

For files:

```
ITEM_PIPELINES = {'scrapy.pipelines.files.FilesPipeline': 1} 
FILES_STORE = '/path/to/valid/dir'
```

ç„¶å¾Œå¾Œé¢æˆ‘éƒ½ä¸æœƒäº†ï¼Œè¦ç”¨åˆ° item ä½†æ˜¯çœ‹ä¸æ‡‚ï¼Œé€šé€šæŠ„ç¶²è·¯ä¸Šçš„

- #### Item

```
class IUBookPic(scrapy.Item):
    title = scrapy.Field()
    file_urls = scrapy.Field()
    files = scrapy.Field() 
```

- #### Parse

```
def parse(self, response):
    fileurls = response.css('span').xpath('@data-url').getall()
    yield IUBookPic(file_urls=fileurls)
```        

- #### Robot.txt

å¯èƒ½æœƒé‡åˆ°ä¸€å€‹æƒ…æ³æ˜¯ `getting Forbidden by robots.txt:`

å‰é¢çš„ user-agent ä¸€å®šè¦è¨­å®šå¥½

ç„¶å¾Œåœ¨ `setting.py` è£¡åŠ ä¸Š

`ROBOTSTXT_OBEY=False`

Source: [Scrapy](https://docs.scrapy.org/en/latest/index.html)

Source: [Scraping images with Python and Scrapy](https://www.pyimagesearch.com/2015/10/12/scraping-images-with-python-and-scrapy/)

Source: [getting Forbidden by robots.txt: scrapy](https://stackoverflow.com/questions/37274835/getting-forbidden-by-robots-txt-scrapy)

---

å¥½åƒæœ‰è¦æ‰“ä»€éº¼ä¸Šä¾†ï¼Œä½†å¿˜äº†ï¼Œç­‰è¨˜å¾—äº†å†è£œå……å§

æƒ³èµ·ä¾†äº†ï¼Œä»Šå¤©æµ·å ±åˆ°äº†å•Šï¼ï¼ï¼

æˆ‘å¥½èˆˆå¥®å•Šå•Šå•Šå•Šå•Šï½ï½ï½ï¼ï¼ï¼

---

æ‰“ä¸€ç¯‡æ–‡ç« çœŸç´¯å•Šï½ï½

è¶ç¾åœ¨é–’é–’æ²’äº‹å¤šæ‰“å¹¾ç¯‡ï¼Œå“ˆå“ˆ

çµ¦è®€åˆ°æœ€å¾Œçš„ä½ ä¸€é»é»çå‹µ
