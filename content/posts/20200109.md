---
title: "1/9 閒聊"
date: 2020-01-10T00:24:54+10:00
draft: false
showDate: true
tags: ["Hugo", "Python", "scrapy", "pip"]
---

# DebugXPythonXCrawler

<!--more-->

先來首歌吧，曾經蔚藍，台灣限定 💜💙

{{< youtube TRTquokWSCw >}}

# Debug

昨天差點 debug 到崩潰，完全不知道出了什麼錯誤

因為 bug 無法重現，所以之後出現再補圖吧

東翻西找，原本以為是 theme 的 layout 有問題

搞了半天結果不是 QQ

## bug

> Mixed content error

最崩潰的是，開發者模式完全無法找到 bug 是怎麼發生的

出現的位置是 `(index):1 error` 也就是 `<!DOCTYPE html>`

完全問號，不知道怎麼處理 T T 

## Solution

後來找到的答案是把 baseURL 改掉

從 `baseURL= 'https://kl23711579.github.io/blog'` 變成 `baseURL= '/blog'`

這樣就可以了

理由呢，完全不知道，真真正正的技術債啊～

Source: [Theme breaks with https? [SOLVED by baseURL = //example.com]](https://discourse.gohugo.io/t/theme-breaks-with-https-solved-by-baseurl-example-com/16427)

# Python and pip

今天因為要寫個爬蟲(整天有事沒事都在寫爬蟲)，想說順便要練習 python

所以選擇了 scrapy，一安裝下去就是悲劇的開始啊

因為 dependence 太多了，所以 pip 變得很難管理

再加上 pip 沒設定好，還是繼續用 python2，也要重新設定

所以花了很長一段時間重新設定 python

## Setup python and pip

首先要先確定 terminal 是用什麼 shell，我的是 zsh，所以要更改 `.zshrc` 這個檔案

加上這兩行

```
alias python='python3'
alias pip='pip3'
```

In this situation, if we input `python` in terminal, it will execute `python3`.

And if we input `pip` in terminal, it will execute `pip3`.

然後 python 建議用 homebrew 管理

Source: [The right and wrong way to set Python 3 as default on a Mac](https://opensource.com/article/19/5/python-3-default-mac)

## Virtual environment

In order to manage the dependence of the module, I deceide to adopt `virtualenv`.

This tool can create an isolated Python environment, so you can manage dependence in this environment.

### Install

`pip install --user virtualenv`

> It is discourage to use `sudo` to install module.

### Usage

- #### Create

`virtualenv temp`

It will create a directory `temp`

- #### Start virtual envuronment

`source temp/bin/activate`

This will change your `$PATH` so its first entry is the virtualenv’s `bin/` directory. (You have to use source because it changes your shell environment in-place.) 

Now, when you install any module with `pip`, it belongs to this virtual environment.

- #### Leave virtual envuronment

`deactivate`

This command is used to leave the virtual environment.

- #### Output module

`pip freeze > requirement.txt`

- #### Remove the virtual environment

Make sure you leave the virtual environment

`rm -r temp`

剩下進階的用法就去查 [document](https://virtualenv.pypa.io/en/stable/userguide/) 吧！！！

> macos 可以用 [virtualenvwrapper](https://virtualenvwrapper.readthedocs.io/en/latest/index.html) 來管理 virtualenv，好用！！！

![20200109-1](/blog/img/20200109/20200109-1.png)

Source1: [Virtualenv Guide](https://virtualenv.pypa.io/en/stable/userguide/)

Source2: [Python_Virtualenv 簡單筆記](https://tech.r567tw.tw/python_virtualenv-%E7%B0%A1%E5%96%AE%E7%AD%86%E8%A8%98/)

## Removing dependencies

就是想要整理 module 但是不知道哪個可以刪哪個不可以，所以很麻煩

原本有一個 `pip-autoremove` 的 module 可以用，但是作者好像放棄更新了(abandon)

所以在 python3 會有問題，對，我就是用了然後產生問題

雖然說會有問題，但還是可以用這個來尋找 dependencies，再一個一個手動刪除(超級麻煩)

`pip-autoremove -l <module>`

然後把列出來的 module 手動一個一個刪除

![20200109-2](/blog/img/20200109/20200109-2.png)

### Warning  

> 千萬不要用 pip-autoremove 去移除 module，情況會變異常複雜

Source: [stackoverflow](https://stackoverflow.com/questions/57470523/pip-uninstall-package-and-unique-dependencies)

Source: [pip-autoremove](https://github.com/invl/pip-autoremove)

## pipdeptree

就是把 dependencies 用樹狀的概念表示出來

`pip install pipdeptree`

使用方法去看 [document](https://github.com/naiquevin/pipdeptree)，這裡來說如何輸出成 graph

有四個指令可以用

```
$ pipdeptree --graph-output dot > dependencies.dot
$ pipdeptree --graph-output pdf > dependencies.pdf
$ pipdeptree --graph-output png > dependencies.png
$ pipdeptree --graph-output svg > dependencies.svg
```

這個要安裝 [`GraphViz`](https://graphviz.org/)

`brew install GraphViz`

`pip install --user GraphViz`

兩個都要打！！！

一開始只打一個，害我搞超久QQ

Source: [pipdeptree](https://github.com/naiquevin/pipdeptree)

# Scrapy

就是爬蟲

## Install

`pip install scrapy`

> 強烈建議使用 virtual environment 安裝

### Create Project

`scrapy startproject IUBook`

然後在 spider 資料夾底下寫自己的爬蟲

`touch IUBook/spiders/book_spider.py`

打程式，照官網上[範例](https://docs.scrapy.org/en/latest/intro/tutorial.html#our-first-spider)自己改就好了

### Cookie and Headers

先設定好 cookies 和 headers，等 request 時一起送出去

```
cookies={'GUEST_PASSWORD': '000000'}
headers={'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11'}
```
```
yield scrapy.Request(url=url, headers=headers, cookies=cookies, callback=self.parse)
```

### Start

`scrapy crawl book`

`book` 是因為我名字取 book

`name= "book"`

### Downloading Files [[link]](https://docs.scrapy.org/en/latest/topics/media-pipeline.html)

在 scrapy 裡是使用 `FilesPipeline` 來下載

- #### Setup

put this in `setting.py`

For image:
```
ITEM_PIPELINES = {'scrapy.pipelines.images.ImagesPipeline': 1}
IMAGES_STORE = '/path/to/valid/dir'
```

For files:

```
ITEM_PIPELINES = {'scrapy.pipelines.files.FilesPipeline': 1} 
FILES_STORE = '/path/to/valid/dir'
```

然後後面我都不會了，要用到 item 但是看不懂，通通抄網路上的

- #### Item

```
class IUBookPic(scrapy.Item):
    title = scrapy.Field()
    file_urls = scrapy.Field()
    files = scrapy.Field() 
```

- #### Parse

```
def parse(self, response):
    fileurls = response.css('span').xpath('@data-url').getall()
    yield IUBookPic(file_urls=fileurls)
```        

- #### Robot.txt

可能會遇到一個情況是 `getting Forbidden by robots.txt:`

前面的 user-agent 一定要設定好

然後在 `setting.py` 裡加上

`ROBOTSTXT_OBEY=False`

Source: [Scrapy](https://docs.scrapy.org/en/latest/index.html)

Source: [Scraping images with Python and Scrapy](https://www.pyimagesearch.com/2015/10/12/scraping-images-with-python-and-scrapy/)

Source: [getting Forbidden by robots.txt: scrapy](https://stackoverflow.com/questions/37274835/getting-forbidden-by-robots-txt-scrapy)

---

好像有要打什麼上來，但忘了，等記得了再補充吧

想起來了，今天海報到了啊！！！

我好興奮啊啊啊啊啊～～～！！！

---

打一篇文章真累啊～～

趁現在閒閒沒事多打幾篇，哈哈

給讀到最後的你一點點獎勵
